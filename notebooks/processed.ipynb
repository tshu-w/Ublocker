{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318082e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home1/wangtianshu/universal-blocker\")\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"./data/gittables/\")\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "from joblib import Memory, Parallel, delayed\n",
    "memory = Memory(\"../.cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f784e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from pyarrow import parquet\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "@memory.cache\n",
    "def get_parquet_files(p):\n",
    "    files = list(p.rglob(\"*.parquet\"))\n",
    "    return files\n",
    "\n",
    "@memory.cache\n",
    "def get_column_type_counters():\n",
    "    counter_dict = defaultdict(Counter)\n",
    "    def cal_column_types(f):\n",
    "        try:\n",
    "            schema = parquet.read_schema(f)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        metadata = schema.metadata\n",
    "        gittables_metadata = json.loads(metadata[b'gittables'].decode(\"utf-8\"))\n",
    "        # print(json.dumps(gittables_metadata, indent=2))\n",
    "\n",
    "        for ann in [\"dbpedia_syntactic_column_types\",\n",
    "                \"schema_syntactic_column_types\",\n",
    "                \"dbpedia_semantic_column_types\",\n",
    "                \"schema_semantic_column_types\"]:\n",
    "            for _, v in gittables_metadata[ann].items():\n",
    "                counter_dict[ann][v[\"cleaned_label\"]] += 1\n",
    "\n",
    "    Parallel(n_jobs=16, require=\"sharedmem\")(delayed(cal_column_types)(f) for f in tqdm(parquet_files))\n",
    "\n",
    "    return counter_dict\n",
    "\n",
    "parquet_files = get_parquet_files(RAW_DIR)\n",
    "counter_dict = get_column_type_counters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6808e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from pyarrow import parquet\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def cal_column_types(f):\n",
    "    try:\n",
    "        schema = parquet.read_schema(f)\n",
    "    except Exception:\n",
    "        return\n",
    "    \n",
    "    metadata = schema.metadata\n",
    "    gittables_metadata = json.loads(metadata[b'gittables'].decode(\"utf-8\"))\n",
    "#     print(json.dumps(gittables_metadata, indent=2))\n",
    "    if len(gittables_metadata[\"dbpedia_syntactic_column_types\"]) > 1:\n",
    "\n",
    "#         print(gittables_metadata[\"dbpedia_syntactic_column_types\"])\n",
    "        if gittables_metadata[\"csv_url\"].startswith(\"https://github.com/alixaxel/dump.HN\"):\n",
    "            return\n",
    "\n",
    "        df = pd.read_parquet(f)\n",
    "        \n",
    "        if list(df.columns) == ['ID', 'Type', 'Story', 'Parent', 'Points', 'Comments', 'Author',\n",
    "       'Title', 'URL', 'Content', 'Created']:\n",
    "            print(gittables_metadata[\"csv_url\"])\n",
    "\n",
    "        print(f)\n",
    "        print(gittables_metadata[\"csv_url\"])\n",
    "        print(df)\n",
    "        print()\n",
    "        \n",
    "        #         return f\n",
    "\n",
    "# print(len(list(filter(lambda x: x is not None, Parallel(n_jobs=16)(delayed(cal_column_types)(f) for f in parquet_files)))))\n",
    "\n",
    "Parallel(n_jobs=1)(delayed(cal_column_types)(f) for f in random.sample(parquet_files, 10))\n",
    "# Parallel(n_jobs=1)(delayed(cal_column_types)(f) for f in [Path(\"data/gittables/raw/id_tables_licensed/FM-405_20171211_00-23.parquet\")])\n",
    "\n",
    "# TODO:\n",
    "# 1. remove no ascii/english tables data/gittables/raw/id_tables_licensed/%EA%B0%B8%EC%98%A4%20%EC%B9%B4%ED%98%B8%203%20%E7%99%BA%E8%A6%8B%EF%BC%81%E3%81%B5%E3%81%9F%E3%82%8A%E3%81%AE%E5%85%B1%E9%80%9A%E7%82%B9_1.parquet\n",
    "# 2. remove all number tables data/gittables/raw/id_tables_licensed/gw_19758.parquet data/gittables/raw/terminal_velocity_tables_licensed/result_23.parquet\n",
    "#    str columns <= number columns / 3 data/gittables/raw/id_tables_licensed/0022000842_1.parquet\n",
    "# 3. 高度相似表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1393f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/gittables/processed/\"\n",
    "from datasets.load import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tables = load_dataset(\n",
    "    \"json\",\n",
    "    data_dir=data_dir,\n",
    "    split=\"train\",\n",
    "    streaming=True,\n",
    ")\n",
    "tables = tables.with_format(\"torch\")\n",
    "dataloader = DataLoader(\n",
    "    dataset=tables,\n",
    "    batch_size=128,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "prefix_dir = Path(\"./data/gittables/raw_4943312/\")   \n",
    "for i, batch in tqdm(enumerate(dataloader)):\n",
    "    if i >= 2400 and i <= 2500:\n",
    "        files = set(batch[\"_file\"])\n",
    "        for f in files:\n",
    "            f = prefix_dir / f\n",
    "            df = pd.read_parquet(f)\n",
    "            print(df.iloc[0].to_json(orient=\"records\")[1:-1], end=\"\\n\\n\")\n",
    "\n",
    "#         print(batch[\"_file\"])\n",
    "    if i > 2600:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d2773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from pyarrow import parquet\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def cal_column_types(f):\n",
    "    try:\n",
    "        schema = parquet.read_schema(f)\n",
    "    except Exception:\n",
    "        return\n",
    "    \n",
    "    metadata = schema.metadata\n",
    "    gittables_metadata = json.loads(metadata[b'gittables'].decode(\"utf-8\"))\n",
    "#     print(json.dumps(gittables_metadata, indent=2))\n",
    "    if len(gittables_metadata[\"dbpedia_syntactic_column_types\"]) > 1:\n",
    "        print(gittables_metadata[\"dbpedia_syntactic_column_types\"])\n",
    "\n",
    "#         print(gittables_metadata[\"dbpedia_syntactic_column_types\"])\n",
    "        if gittables_metadata[\"csv_url\"].startswith(\"https://github.com/alixaxel/dump.HN\"):\n",
    "            return\n",
    "\n",
    "        df = pd.read_parquet(f)\n",
    "        \n",
    "        if list(df.columns) == ['ID', 'Type', 'Story', 'Parent', 'Points', 'Comments', 'Author',\n",
    "       'Title', 'URL', 'Content', 'Created']:\n",
    "            print(gittables_metadata[\"csv_url\"])\n",
    "\n",
    "        print(f)\n",
    "        print(gittables_metadata[\"csv_url\"])\n",
    "        print(df)\n",
    "        print()\n",
    "        \n",
    "        #         return f\n",
    "\n",
    "# print(len(list(filter(lambda x: x is not None, Parallel(n_jobs=16)(delayed(cal_column_types)(f) for f in parquet_files)))))\n",
    "\n",
    "# Parallel(n_jobs=1)(delayed(cal_column_types)(f) for f in random.sample(parquet_files, 10))\n",
    "Parallel(n_jobs=1)(delayed(cal_column_types)(f) for f in [Path(\"data/gittables/raw/id_tables_licensed/FM-405_20171211_00-23.parquet\")])\n",
    "\n",
    "# TODO:\n",
    "# 1. remove no ascii/english tables data/gittables/raw/id_tables_licensed/%EA%B0%B8%EC%98%A4%20%EC%B9%B4%ED%98%B8%203%20%E7%99%BA%E8%A6%8B%EF%BC%81%E3%81%B5%E3%81%9F%E3%82%8A%E3%81%AE%E5%85%B1%E9%80%9A%E7%82%B9_1.parquet\n",
    "# 2. remove all number tables data/gittables/raw/id_tables_licensed/gw_19758.parquet data/gittables/raw/terminal_velocity_tables_licensed/result_23.parquet\n",
    "#    str columns <= number columns / 3 data/gittables/raw/id_tables_licensed/0022000842_1.parquet\n",
    "# 3. 高度相似表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155bc4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df729dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
